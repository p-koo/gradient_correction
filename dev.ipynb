{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py, os\n",
    "import numpy as np\n",
    "from six.moves import cPickle\n",
    "import argparse\n",
    "import tensorflow as tf\n",
    "import model_zoo\n",
    "\n",
    "#-----------------------------------------------------------------\n",
    "\n",
    "\n",
    "def get_data(path, dataset='test'):\n",
    "    with h5py.File(path, \"r\") as f:\n",
    "        x = f[\"/deepsea/\"+dataset+\"/features\"][:].astype(np.float32)\n",
    "        y = f[\"/deepsea/\"+dataset+\"/labels\"][:].astype(np.float32)\n",
    "    return x, y\n",
    "\n",
    "#-----------------------------------------------------------------\n",
    "\n",
    "model_names = ['deepsea', 'basset', 'deepsea_custom', 'basset_custom']\n",
    "activations = ['relu', 'exponential']\n",
    "trial = 0\n",
    "\n",
    "# set paths\n",
    "results_path = '../results_deepsea'\n",
    "if not os.path.exists(results_path):\n",
    "    os.makedirs(results_path)\n",
    "\n",
    "# load data\n",
    "data_path = '../../data'\n",
    "\n",
    "filepath = os.path.join(data_path, 'deepsea_dataset.h5')\n",
    "x_test, y_test = get_data(filepath, dataset='test')\n",
    "\n",
    "# get shapes\n",
    "N, L, A = x_test.shape\n",
    "num_labels = y_test.shape[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# build model\n",
    "print(model_name)\n",
    "if model_name == 'deepsea':\n",
    "    model = model_zoo.deepsea((L,A), num_labels, activation)\n",
    "elif model_name == 'danq':\n",
    "    model = model_zoo.danq((L,A), num_labels, activation)\n",
    "elif model_name == 'basset':\n",
    "    model = model_zoo.basset((L,A), num_labels, activation)\n",
    "elif model_name == 'deepatt':\n",
    "    model = model_zoo.deepatt((L,A), num_labels, activation)\n",
    "elif model_name == 'cnn_att':\n",
    "    model = model_zoo.cnn_att((L,A), num_labels, activation)\n",
    "elif model_name == 'cnn_lstm_trans_1':\n",
    "    model = model_zoo.cnn_lstm_trans((L,A), num_labels, activation, num_layers=1)\n",
    "elif model_name == 'cnn_lstm_trans_2':\n",
    "    model = model_zoo.cnn_lstm_trans((L,A), num_labels, activation, num_layers=2)\n",
    "elif model_name == 'cnn_lstm_trans_4':\n",
    "    model = model_zoo.cnn_lstm_trans((L,A), num_labels, activation, num_layers=4)\n",
    "elif model_name == 'cnn_trans_1':\n",
    "    model = model_zoo.cnn_trans((L,A), num_labels, activation, num_layers=1)\n",
    "elif model_name == 'cnn_trans_2':\n",
    "    model = model_zoo.cnn_trans((L,A), num_labels, activation, num_layers=2)\n",
    "elif model_name == 'cnn_trans_4':\n",
    "    model = model_zoo.cnn_trans((L,A), num_labels, activation, num_layers=4)\n",
    "elif model_name == 'deepsea_custom':\n",
    "    model = model_zoo.deepsea_custom((L,A), num_labels, activation)\n",
    "elif model_name == 'danq_custom':\n",
    "    model = model_zoo.danq_custom((L,A), num_labels, activation)\n",
    "elif model_name == 'basset_custom':\n",
    "    model = model_zoo.basset_custom((L,A), num_labels, activation)\n",
    "else:\n",
    "    print(\"can't find model\")\n",
    "\n",
    "model_name = model_name + '_' + activation + '_' + str(trial)\n",
    "\n",
    "# compile model model\n",
    "auroc = tf.keras.metrics.AUC(curve='ROC', name='auroc')\n",
    "aupr = tf.keras.metrics.AUC(curve='PR', name='aupr')\n",
    "model.compile(tf.keras.optimizers.Adam(0.001), loss='binary_crossentropy', metrics=[auroc, aupr])\n",
    "\n",
    "# save model params\n",
    "model_dir = os.path.join(results_path, model_name+'_weights.h5')\n",
    "model.load_weights(model_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43730"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tfomics import impress\n",
    "from tfomics import explain\n",
    "\n",
    "X = x_test[::45][:10000]\n",
    "        \n",
    "# instantiate explainer class\n",
    "explainer = explain.Explainer(model)\n",
    "\n",
    "# calculate attribution maps\n",
    "saliency_scores = explainer.saliency_maps(X)\n",
    "smoothgrad_scores = explainer.smoothgrad(X, num_samples=25, mean=0.0, stddev=0.1)\n",
    "intgrad_scores = explainer.integrated_grad(X, baseline_type='zeros')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
